{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas-Library\n",
    "\n",
    "Pandas is a Python library for data analysis and manipulation, most notably table-formatted data.\n",
    "\n",
    "Since pandas is an additional library, it needs to be imported first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # Canonical import of pandas as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas supports two major data structures:\n",
    "\n",
    "- DataFrames: rectangular data tables\n",
    "- Series: serial data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series\n",
    "\n",
    "Series are one-dimensional (array-like) data structures, useful for single data columns.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a series from a list, with standard index\n",
    "s = pd.Series(data = [0,1,4,9,16])\n",
    "# Display\n",
    "s.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrames\n",
    "\n",
    "DataFrame can be created from lists or matrices and imported from data, e.g. csv-Files.\n",
    "\n",
    "An example DataFrame looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe from list of lists with explicitly named columns\n",
    "# Since the command stems from the pandas-library, we have to call pd.DataFrame\n",
    "df = pd.DataFrame(data = [[1, 2, 3], [4, 5, 6]], columns = ['A', 'B', 'C'])\n",
    "# Show the top lines (.head()) of dataframe\n",
    "# Since we apply .head() to the dataframe df, we call df.head()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More frequently, we will import datasets from various sources, in the following command we read the list of all stations in Germany in CSV-format (.read_csv() from Pandas):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    'http://download-data.deutschebahn.com/static/datasets/haltestellen/D_Bahnhof_2017_09.csv',\n",
    "    sep = ';', # Separator default is \",\"\n",
    "    decimal=\",\") # German decimal separator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a good idea to initially look at the import in order to know the structure, i.e. column names and data fields. This is where ```df.head()```comes in handy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pandas syntax allows for very efficient filtering of the data. In order to access only a single column, we can use ```df[column_name]``` where ```column_name```is one of the above columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['NAME'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To quickly learn about the data set at hand, we can use inbuilt functions:\n",
    "\n",
    "- ```df.describe()``` - mostly for numerical data\n",
    "- ```df.info()``` to provide information on columns and data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Display the **DS100** column of the dataset only. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It also possible to filter for certain content, e.g. to find the names of all long distance stations (showing 'FV' in the 'VERKEHR'-column):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['VERKEHR'] == 'FV'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily, pandas DataFrames accept this list of True/False as argument to restrict the returned values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['VERKEHR'] == 'FV'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By adding a second argument in square brackets, we can return only the columns we are interested in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['VERKEHR'] == 'FV']['DS100'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be used in many ways, e.g. to count how many long distance stations there are in Germany?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['VERKEHR'] == 'FV']['NAME'].count() #It suffices to count one colum only..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By concatenating multiple commands, we can list all stations with Berlin in their name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['NAME'].str.contains('Berlin')]['NAME'].head(10) \n",
    "# Notice we can have more lines displayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name, Latitude and Longitude of 'Berlin' Stations - most of them are actually in Berlin..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter and save returned dataframe in new variable:\n",
    "df2 = df[df['NAME'].str.contains('Berlin')][['NAME', 'LAENGE', 'BREITE']]\n",
    "# Display the first few lines:\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the ```sort_values```to find southernmost 'Berlin' station. Here, ```inplace``` means that we manipulate the variable in memory. While this is not critical for smaller data sets, Pandas is generally open for Terabytes where the additional memory would hurt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.sort_values('BREITE', inplace = True, ascending = True)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to export the resulting data frames, e.g. to JSON (```df2.to_json('filename.json')```) or to Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_excel('BerlinStations.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can read data from AWS cloud storage (S3) - in this case we use test data of our railway challenge locomotive *Emma*.\n",
    "\n",
    "The dataset contains:\n",
    "\n",
    "- $x$: Longitude\n",
    "- $y$: Latitude\n",
    "- $z$: Altitude (m above sea level)\n",
    "- $v$: velocity (m/s)\n",
    "\n",
    "All data recorded in $1$ Hz frequency using an iPad-GPS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('https://s3-eu-west-1.amazonaws.com/ifvworkshopdata/emma1000.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using the ```plot()```-function, we can obtain a rough estimate of the velocity distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['v'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently, the GPS has $v = -1$-readings as long as it is acquiring a position. We filter these out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['v'] >= 0]['v'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise:\n",
    "\n",
    "1. Load the open data set on platform height and length from: http://download-data.deutschebahn.com/static/datasets/bahnsteig/DBSuS-Bahnsteigdaten-Stand2020-03.csv\n",
    "1. Inspect the dataset\n",
    "1. Find the longest (```df[column_name].max()```) and shortest() (```df[column_name].min()```) platform length ('Netto-baul√§nge (m)')\n",
    "1. Find the associated station number ('Bahnhofsnummer')\n",
    "\n",
    "Extra task: obtain the name by integrating with http://download-data.deutschebahn.com/static/datasets/stationsdaten/DBSuS-Uebersicht_Bahnhoefe-Stand2020-03.csv!\n",
    "\n",
    "Hint: use ```list()``` to obtain return values and access the $0$-th element to obtain a numeric value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
